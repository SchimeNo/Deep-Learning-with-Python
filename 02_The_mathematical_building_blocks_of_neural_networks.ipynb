{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 - The mathematical building blocks of neural networks",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMaAGfD3PXI1TLV8RGIYHIu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchimeNo/Deep-Learning-with-Python/blob/main/02_The_mathematical_building_blocks_of_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94b5S-442Brq"
      },
      "source": [
        "# **02 The mathematical building blocks of neural networks** \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgoHBAC9zlEJ"
      },
      "source": [
        "#!pip install keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-9eaKfSzXQ-"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JyzFHif2JVa",
        "outputId": "6ce68ec6-f9ce-4a9e-c704-e38e7c27a838"
      },
      "source": [
        "print(\"Shape:\", train_images.shape,\"Length:\", len(train_labels),\"Array:\", train_labels,sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:\n",
            "(60000, 28, 28)\n",
            "Length:\n",
            "60000\n",
            "Array:\n",
            "[5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovOxIa44VxN",
        "outputId": "da64d772-142e-4b99-b53e-8b1c39925094"
      },
      "source": [
        "print(\"Shape:\", test_images.shape,\"Length:\", len(test_labels),\"Array:\", test_labels,sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:\n",
            "(10000, 28, 28)\n",
            "Length:\n",
            "10000\n",
            "Array:\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT9IBI70aAPt"
      },
      "source": [
        "## Network architecture\n",
        "\n",
        "**Loss function:**\n",
        "-  How the network will be able to measure its performance on\n",
        "the training data, and thus how it will be able to steer itself in the right direction.\n",
        "\n",
        "**Optimizer:**\n",
        "- The mechanism through which the network will update itself\n",
        "based on the data it sees and its loss function.\n",
        "\n",
        "**Metrics:**\n",
        "- Here, we’ll only care about accuracy (the fraction of the images that were correctly classified).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Du4YyqXfaDHR"
      },
      "source": [
        "# Network architecture\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGP-WrDM-EGO"
      },
      "source": [
        "### The compilation step (optimizer, loss, metric)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSbBV03W4VmP"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CdAkCKb_wFg"
      },
      "source": [
        "### Preparing the image data\n",
        "\n",
        "We’ll transform the data into a float32 array of shape (60000, 28 * 28) with values between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Ard7QY_7zU"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32')/255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaqigZXzBfmC"
      },
      "source": [
        "### Preparing the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOM-sYnM_1Z4"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ7uZr3WCMrB"
      },
      "source": [
        "###Train the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewmcqoFjBvkd",
        "outputId": "0a98fc38-cbbe-4d99-fa7c-bcfa005eeb08"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.4323 - accuracy: 0.8766\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1089 - accuracy: 0.9685\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0695 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0473 - accuracy: 0.9860\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0366 - accuracy: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59751f45d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwUHCz2E5eg"
      },
      "source": [
        "### Use on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta4RD_jVE5Sx",
        "outputId": "bd32fc8a-6465-4b08-f463-0f0b654c29fe"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9806\n",
            "test_acc: 0.06563051789999008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJolVAgx5EOz"
      },
      "source": [
        "# Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFcBo8tOCSVg"
      },
      "source": [
        "\n",
        "\n",
        "Data stored in multidimensional Numpy arrays. It's a container for data—almost always numerical data. So, it’s a\n",
        "container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions\n",
        "(note that in the context of tensors, a dimension is often called an axis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4KP4o4E6qq"
      },
      "source": [
        "\n",
        "#### Scalars (0D tensors)\n",
        "A tensor that contains only one number is called a scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXKgXLgCCi8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01b7089-8fd9-4103-b838-b602e7ea6ac2"
      },
      "source": [
        "import numpy as np\n",
        "x=np.array(12)\n",
        "print(x,\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 \n",
            "dim: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6AmED6KEoo5"
      },
      "source": [
        "#### Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xwafhMUDSbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b095675b-a3eb-4a44-e80a-9a921aff0b9c"
      },
      "source": [
        "x = np.array([12, 3, 6, 14])\n",
        "print(\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRik8O2wFyWU"
      },
      "source": [
        "#### Matrices (2D tensors) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzZ66NGRHrsA",
        "outputId": "c5df9774-32a2-4b37-b6fd-fc5f7d47184b"
      },
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]])\n",
        "print(\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOipDYMMHmuI"
      },
      "source": [
        "#### 3D tensors and higher-dimensional tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EIVVR0FXl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6f4956-5dd3-4f45-a1be-d2397d03eeed"
      },
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]],\n",
        "[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]],\n",
        "[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]]])\n",
        "print(\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1QbHmDmKJBA"
      },
      "source": [
        "In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to\n",
        "5D if you process video data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFqHW0WYEDes"
      },
      "source": [
        "### Key attributes\n",
        "\n",
        "* Number of axes (rank)—For instance, a 3D tensor has three axes, and a matrix has\n",
        "two axes. Also called the tensor’s ndim .\n",
        "* Shape—This is a tuple of integers that describes how many dimensions the tensor has along each axis. \n",
        "* Data type (usually called dtype in Python libraries)—This is the type of the data\n",
        "contained in the tensor.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5scGUcltEDLF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXqpsZSNJ_FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2d17f5-2f07-450a-8e35-8c6b7fe1782d"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.shape)\n",
        "print(train_images.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KD9gk8SG2Od"
      },
      "source": [
        "We have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of\n",
        "60,000 matrices of 28 × 8 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-F6qVC2G_iW"
      },
      "source": [
        "### Displaying a digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IrvMSDfYHhrK",
        "outputId": "07002d2f-878c-489e-8c3f-4d6b69152e6e"
      },
      "source": [
        "digit = train_images[10000]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.gist_earth)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUM2Dv0_KLOY"
      },
      "source": [
        "###  Manipulating tensors in Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucptmaX-Ibt4",
        "outputId": "13f71e2a-5692-4412-b0ca-0aaf65a3dc6b"
      },
      "source": [
        "my_slice=train_images[10:100]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eHME5B7JEmH"
      },
      "source": [
        "####  select 14 × 14 pixels in the bottom-right corner of all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYo_DQjTIjW1",
        "outputId": "7014096d-a93e-430e-b9c7-da799fd535ed"
      },
      "source": [
        "my_slice=train_images[:,14:,14:]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 14, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqUfUhfPJLJc"
      },
      "source": [
        "#### crop the images to patches of 14 × 14 pixels centered in the middle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP8LoeVvI5Rb"
      },
      "source": [
        "my_slice=train_images[:,7:-7, 7:-7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDiPX-iJJ9Ak"
      },
      "source": [
        "### Data batches\n",
        "The first axis will be the samples axis. In the MNIST example, samples are images of digits.\n",
        "\n",
        "In, deep-learning models don’t process an entire dataset at once; rather,\n",
        "they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with batch size of 128\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJuoc0GJsV2"
      },
      "source": [
        "batch = train_images[:128]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KZh-49hKysO"
      },
      "source": [
        "### Real-world examples of data tensors\n",
        "Vector data—2D tensors of shape (samples, features)\n",
        "* Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
        "features)\n",
        "* Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
        "channels, height, width)\n",
        "* Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
        "(samples, frames, channels, height, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn3QQoi8Kym8"
      },
      "source": [
        "# Tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1dyi1JXnZvn"
      },
      "source": [
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] = max(x[i, j], 0)\n",
        "  return x\n",
        "\n",
        "def naive_add(x,y):\n",
        "  assert len(x.shape)==2\n",
        "  assert x.shape == y.shape\n",
        "  x=x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j] += y[i,j]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynwrS2WaKp0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e12c957a-2669-47a6-ad8f-36fee7470449"
      },
      "source": [
        "#Keras layer instance\n",
        "keras.layers.Dense(512, activation='relu')\n",
        "\n",
        "#new representation for the input tensor (where W is a 2D tensor and b is a vector)\n",
        "output=naive_relu(naive_add(W, input)+b)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-2f542e17584f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#new representation for the input tensor (where W is a 2D tensor and b is a vector)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnaive_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIghUw_PaKy6"
      },
      "source": [
        "* dot: product between the input tensor and a tensor named W\n",
        "* (+) : addition (+) between the resulting 2D tensor and a vector b\n",
        "+  relu(x):  rectified linear unit,  this returns the standard ReLU activation max(x, 0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi2pX9CEbAFV"
      },
      "source": [
        "import numpy as np\n",
        "#Element-wise addition\n",
        "z= x + y\n",
        "#Element-wise relu\n",
        "z = np.maximum(z,0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MBDNC8sZhx"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "What happens with addition when the shapes of the two tensors\n",
        "being added differ?\n",
        "\n",
        "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
        "\n",
        "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKYl4Qd2hd_2"
      },
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 2\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j]+=y[j]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKd27N2Hgcd2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27VlwJlfgcXi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}