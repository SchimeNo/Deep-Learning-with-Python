{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 - The mathematical building blocks of neural networks",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3sIhuqDeKR/x3R3PmAMgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchimeNo/Deep-Learning-with-Python/blob/main/02_The_mathematical_building_blocks_of_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94b5S-442Brq"
      },
      "source": [
        "# **02 The mathematical building blocks of neural networks** \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgoHBAC9zlEJ"
      },
      "source": [
        "#!pip install keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-9eaKfSzXQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "bc7d816c-4938-4dfe-8458-f6556fbbd513"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JyzFHif2JVa",
        "collapsed": true,
        "outputId": "411a1f25-69dd-4dd4-a8c7-37ea0ebd9e04"
      },
      "source": [
        "print(\"Shape:\", train_images.shape,\"Length:\", len(train_labels),\"Array:\", train_labels,sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:\n",
            "(60000, 28, 28)\n",
            "Length:\n",
            "60000\n",
            "Array:\n",
            "[5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovOxIa44VxN",
        "collapsed": true,
        "outputId": "746554d9-53c4-43b5-eb5a-3a15b947fcea"
      },
      "source": [
        "print(\"Shape:\", test_images.shape,\"Length:\", len(test_labels),\"Array:\", test_labels,sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:\n",
            "(10000, 28, 28)\n",
            "Length:\n",
            "10000\n",
            "Array:\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT9IBI70aAPt"
      },
      "source": [
        "## Network architecture\n",
        "\n",
        "**Loss function:**\n",
        "-  How the network will be able to measure its performance on\n",
        "the training data, and thus how it will be able to steer itself in the right direction.\n",
        "\n",
        "**Optimizer:**\n",
        "- The mechanism through which the network will update itself\n",
        "based on the data it sees and its loss function.\n",
        "\n",
        "**Metrics:**\n",
        "- Here, we’ll only care about accuracy (the fraction of the images that were correctly classified).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Du4YyqXfaDHR"
      },
      "source": [
        "# Network architecture\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGP-WrDM-EGO"
      },
      "source": [
        "### The compilation step (optimizer, loss, metric)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSbBV03W4VmP"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CdAkCKb_wFg"
      },
      "source": [
        "### Preparing the image data\n",
        "\n",
        "We’ll transform the data into a float32 array of shape (60000, 28 * 28) with values between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Ard7QY_7zU"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32')/255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaqigZXzBfmC"
      },
      "source": [
        "### Preparing the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOM-sYnM_1Z4"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ7uZr3WCMrB"
      },
      "source": [
        "###Train the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewmcqoFjBvkd",
        "collapsed": true,
        "outputId": "5312dfca-45cb-455e-9514-eda02bf48e41"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.4205 - accuracy: 0.8771\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1127 - accuracy: 0.9671\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0723 - accuracy: 0.9785\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0504 - accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0366 - accuracy: 0.9885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec45e55d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwUHCz2E5eg"
      },
      "source": [
        "### Use on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta4RD_jVE5Sx",
        "collapsed": true,
        "outputId": "fca175b6-f733-4908-ad88-f86371b7e3b9"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9794\n",
            "test_acc: 0.06788118928670883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJolVAgx5EOz"
      },
      "source": [
        "# 2.2 Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFcBo8tOCSVg"
      },
      "source": [
        "\n",
        "\n",
        "Data stored in multidimensional Numpy arrays. It's a container for data—almost always numerical data. So, it’s a\n",
        "container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions\n",
        "(note that in the context of tensors, a dimension is often called an axis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4KP4o4E6qq"
      },
      "source": [
        "\n",
        "#### Scalars (0D tensors)\n",
        "A tensor that contains only one number is called a scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXKgXLgCCi8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1a272ac7-e10b-4976-d4a8-e996beb9d5c0"
      },
      "source": [
        "import numpy as np\n",
        "x=np.array(12)\n",
        "print(x,\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 \n",
            "dim: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6AmED6KEoo5"
      },
      "source": [
        "#### Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xwafhMUDSbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fab84222-2b6f-4cef-bf1e-330ff32a0523"
      },
      "source": [
        "x = np.array([12, 3, 6, 14])\n",
        "print(\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRik8O2wFyWU"
      },
      "source": [
        "#### Matrices (2D tensors) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzZ66NGRHrsA",
        "collapsed": true,
        "outputId": "2e25ec5a-1160-4139-83ea-18993e88ff0f"
      },
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]])\n",
        "print(\"\\ndim:\", x.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOipDYMMHmuI"
      },
      "source": [
        "#### 3D tensors and higher-dimensional tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EIVVR0FXl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "00b5abeb-7880-4873-9ade-6b198b70a7af"
      },
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]],\n",
        "[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]],\n",
        "[[5, 78, 2, 34, 0],\n",
        "[6, 79, 3, 35, 1],\n",
        "[7, 80, 4, 36, 2]]])\n",
        "print(\"\\ndim:\", x.ndim)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dim: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1QbHmDmKJBA"
      },
      "source": [
        "In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to\n",
        "5D if you process video data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFqHW0WYEDes"
      },
      "source": [
        "### Key attributes\n",
        "\n",
        "* Number of axes (rank)—For instance, a 3D tensor has three axes, and a matrix has\n",
        "two axes. Also called the tensor’s ndim .\n",
        "* Shape—This is a tuple of integers that describes how many dimensions the tensor has along each axis. \n",
        "* Data type (usually called dtype in Python libraries)—This is the type of the data\n",
        "contained in the tensor.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5scGUcltEDLF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXqpsZSNJ_FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "169fd0d2-5774-45c7-e2ab-b1fb9eddac67"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.shape)\n",
        "print(train_images.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KD9gk8SG2Od"
      },
      "source": [
        "We have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of\n",
        "60,000 matrices of 28 × 8 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-F6qVC2G_iW"
      },
      "source": [
        "### Displaying a digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IrvMSDfYHhrK",
        "collapsed": true,
        "outputId": "6b80c63a-7b8d-4190-8129-5f1d536bbd1c"
      },
      "source": [
        "digit = train_images[10000]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.gist_earth)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUM2Dv0_KLOY"
      },
      "source": [
        "###  Manipulating tensors in Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucptmaX-Ibt4",
        "collapsed": true,
        "outputId": "53b58e8d-5ed6-4391-e6d8-3bdd65bc973c"
      },
      "source": [
        "my_slice=train_images[10:100]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eHME5B7JEmH"
      },
      "source": [
        "####  select 14 × 14 pixels in the bottom-right corner of all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYo_DQjTIjW1",
        "collapsed": true,
        "outputId": "3ceff503-cc6c-427c-ee97-f8f13d4eaac5"
      },
      "source": [
        "\n",
        "my_slice=train_images[:,14:,14:]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 14, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqUfUhfPJLJc"
      },
      "source": [
        "#### crop the images to patches of 14 × 14 pixels centered in the middle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP8LoeVvI5Rb"
      },
      "source": [
        "my_slice=train_images[:,7:-7, 7:-7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDiPX-iJJ9Ak"
      },
      "source": [
        "### Data batches\n",
        "The first axis will be the samples axis. In the MNIST example, samples are images of digits.\n",
        "\n",
        "In, deep-learning models don’t process an entire dataset at once; rather,\n",
        "they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with batch size of 128\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJuoc0GJsV2"
      },
      "source": [
        "batch = train_images[:128]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KZh-49hKysO"
      },
      "source": [
        "### Real-world examples of data tensors\n",
        "Vector data—2D tensors of shape (samples, features)\n",
        "* Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
        "features)\n",
        "* Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
        "channels, height, width)\n",
        "* Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
        "(samples, frames, channels, height, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn3QQoi8Kym8"
      },
      "source": [
        "# 2.3 Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIghUw_PaKy6"
      },
      "source": [
        "* dot: product between the input tensor and a tensor named W\n",
        "* (+) : addition (+) between the resulting 2D tensor and a vector b\n",
        "+  relu(x):  rectified linear unit,  this returns the standard ReLU activation max(x, 0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1dyi1JXnZvn"
      },
      "source": [
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] = max(x[i, j], 0)\n",
        "  return x\n",
        "\n",
        "def naive_add(x,y):\n",
        "  assert len(x.shape)==2\n",
        "  assert x.shape == y.shape\n",
        "  x=x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j] += y[i,j]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynwrS2WaKp0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ad0e18e4-26f7-467f-a833-eeb39df8c4d3"
      },
      "source": [
        "\n",
        "\n",
        "#Keras layer instance\n",
        "layers.Dense(512, activation='relu')\n",
        "\n",
        "#new representation for the input tensor (where W is a 2D tensor and b is a vector)\n",
        "\n",
        "# output=naive_relu(naive_add(W, input)+b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7fec3e4a9f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MBDNC8sZhx"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "What happens with addition when the shapes of the two tensors\n",
        "being added differ?\n",
        "\n",
        "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
        "\n",
        "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKYl4Qd2hd_2"
      },
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 2\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j]+=y[j]\n",
        "  return \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSlDfUfy8Q1G",
        "collapsed": true,
        "outputId": "93456e00-b665-42ea-ece3-997ea2bd3aed"
      },
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)\n",
        "\n",
        "# output z has shape (64, 3, 32, 10) like x\n",
        "z.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 3, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKiChfsnMlr9"
      },
      "source": [
        "## Tensor dot\n",
        "\n",
        "also called a tensor product, is the most useful tensor operation. In both Numpy and Keras it’s done using the standard dot operator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKd27N2Hgcd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "collapsed": true,
        "outputId": "993c478f-b856-4264-d1ea-ece1f70dc98a"
      },
      "source": [
        "import numpy as np\n",
        "z = np.dot(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-23794a0e501f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (64,3,32,10) and (32,10) not aligned: 10 (dim 3) != 32 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27VlwJlfgcXi"
      },
      "source": [
        "# VECTOR\n",
        "def naive_vector_dot(x, y):\n",
        "  assert len(x.shape) == 1\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[0] == y.shape[0]\n",
        "  z = 0.\n",
        "  for i in range(x.shape[0]):\n",
        "    z += x[i] * y[i]\n",
        "  return z\n",
        "\n",
        "# MATRIX\n",
        "import numpy as np\n",
        "def naive_matrix_vector_dot(x, y):\n",
        "  z = np.zeros(x.shape[0])\n",
        "  for i in range(x.shape[0]):\n",
        "    z[i] = naive_vector_dot(x[i, :], y)\n",
        "  return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTPOpCfzCUxB"
      },
      "source": [
        "Note that as soon as one of the two tensors has an ndim greater than 1, dot is no longer symmetric, which is to say that dot(x, y) isn’t the same as dot(y, x)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaRz8ZP3DRJq"
      },
      "source": [
        "## Tensor reshaping\n",
        "\n",
        "Reshaping a tensor means rearranging its rows and columns to match a target shape. Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiFUJSp4CRNA"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgG82HI0D2aa"
      },
      "source": [
        "x = np.array([[0., 1.], [2., 3.], [4., 5.]])\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icTRdXEoD55a"
      },
      "source": [
        "x = x.reshape((6, 1))\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5YuXKnCES55"
      },
      "source": [
        "### Transposing \n",
        " means exchanging its rows and its columns, so that x[i, :] becomes x[:, i]:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhMEiWoGEHmC"
      },
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pR0kS7uEm4o"
      },
      "source": [
        "# 2.4 Gradient-based optimization\n",
        "\n",
        "As you saw in the previous section, each neural layer from our first network example\n",
        "transforms its input data as follows:\n",
        "\n",
        "```\n",
        "output = relu(dot(W, input) + b)\n",
        "```\n",
        "\n",
        "In this expression, W and b are tensors that are attributes of the layer. They’re called\n",
        "the weights or trainable parameters of the layer (the kernel and bias attributes, respectively). These weights contain the information learned by the network from exposure\n",
        "to training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZpkCqq5GaPO"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "1. Draw a batch of training samples x and corresponding targets y.\n",
        "2. Run the network on x (a step called the forward pass) to obtain predictions y_pred.\n",
        "3. Compute the loss of the network on the batch, a measure of the mismatch\n",
        "between y_pred and y.\n",
        "4. Update all weights of the network in a way that slightly reduces the loss on this\n",
        "batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ2q-4ErJduy"
      },
      "source": [
        "## Stochastic gradient descent\n",
        "\n",
        "* A function’s minimum is a point where the derivative is 0\n",
        "* Given a differentiable function, it’s theoretically possible to find its minimum\n",
        "* Applied to a neural network, that means finding analytically the combination of\n",
        "weight values that yields the smallest possible loss function\n",
        "* This can be done by solving the equation gradient(f)(W) = 0 for W. \n",
        "*  If you\n",
        "update the weights in the opposite direction from the gradient, the loss will be a little\n",
        "less every time\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Draw a batch of training samples x and corresponding targets y.\n",
        "2. Run the network on x to obtain predictions y_pred.\n",
        "3. Compute the loss of the network on the batch, a measure of the mismatch\n",
        "between y_pred and y.\n",
        "4. Compute the gradient of the loss with regard to the network’s parameters (a\n",
        "backward pass).\n",
        "5. Move the parameters a little in the opposite direction from the gradient—for\n",
        "example W -= step * gradient—thus reducing the loss on the batch a bit.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-R8dzNFj_v4"
      },
      "source": [
        "# Chapter summary\n",
        "* Learning means finding a combination of model parameters that minimizes a loss function for a given set of training data samples and their corresponding targets.\n",
        "* Learning happens by drawing random batches of data samples and their\n",
        "targets, and computing the gradient of the network parameters with\n",
        "respect to the loss on the batch. The network parameters are then moved\n",
        "a bit (the magnitude of the move is defined by the learning rate) in the\n",
        "opposite direction from the gradient.\n",
        "* The entire learning process is made possible by the fact that neural networks are chains of differentiable tensor operations, and thus it’s possible\n",
        "to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value.\n",
        "* Two key concepts you’ll see frequently in future chapters are loss and optimizers. These are the two things you need to define before you begin feeding data into a network.\n",
        "* The loss is the quantity you’ll attempt to minimize during training, so it\n",
        "should represent a measure of success for the task you’re trying to solve.\n",
        "* The optimizer specifies the exact way in which the gradient of the loss will\n",
        "be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on."
      ]
    }
  ]
}