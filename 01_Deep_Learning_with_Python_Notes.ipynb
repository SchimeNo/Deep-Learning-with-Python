{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - Deep Learning with Python - Notes",
      "provenance": [],
      "authorship_tag": "ABX9TyNNbbRql1xXElcndzTWXbyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SchimeNo/Deep-Learning-with-Python/blob/main/01_Deep_Learning_with_Python_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzC2vYJHJwWZ"
      },
      "source": [
        "# **Deep Learning with Python**\r\n",
        "\r\n",
        "https://tanthiamhuat.files.wordpress.com/2018/03/deeplearningwithpython.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzBQYKAKgfgp"
      },
      "source": [
        "## 01 What is deep learning? ##\r\n",
        "\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQeOxG0glCP"
      },
      "source": [
        "\r\n",
        "**Deep Learning:**\r\n",
        "- Deep learning is a specific subfield of machine learning: a new take on learning representations from data that puts an emphasis on learning successive layers of increasingly meaningful representations. \r\n",
        "\r\n",
        "- The *deep* in deep learning isn’t a reference to any kind of deeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations. How many layers contribute to a model of the data is called the depth of the model.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5SWS2dMhzAo"
      },
      "source": [
        "**Neural Network:**\r\n",
        "-  The term neural network is a reference to neurobiology, but although some of the central concepts in deep learning were developed in part by drawing inspiration from our understanding of the brain, deep-learning models are not models of the brain.\r\n",
        "There’s no evidence that the brain implements anything like the learning mechanisms used in modern deep-learning models. You may come across pop-science articles proclaiming that deep learning works like the brain or was modeled after the brain, but that isn’t the case. \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRgNIas2h9fV"
      },
      "source": [
        "**Logistic Regression:**\r\n",
        "- *logreg* is a classification algorithm rather than a regression\r\n",
        "algorithm\r\n",
        "\r\n",
        "**SVM:**\r\n",
        "- Kernel methods are a group of classification algorithms, the best known of which is the support vector machine (SVM). SVMs aim at solving classification problems by finding good decision boundaries between two sets of points\r\n",
        "belonging to two different categories.\r\n",
        "\r\n",
        "**Decision Tree:**\r\n",
        "- Decision trees are flowchart-like structures that let you classify input data points or predict output values given inputs.\r\n",
        "\r\n",
        "**Random Forest:**\r\n",
        "- A robust, practical take on\r\n",
        "decision-tree learning that involves building a large number of specialized decision trees and then ensembling their outputs. Random forests are applicable to a wide range of problems—you could say that they’re almost always the second-best algorithm for any shallow machine-learning task.\r\n",
        "\r\n",
        "**Gradient Boosting Machine:**\r\n",
        "- Much like a random forest, is a machine-learning\r\n",
        "technique based on ensembling weak prediction models, generally decision trees. It uses gradient boosting, a way to improve any machine-learning model by iteratively training new models that specialize in addressing the weak points of the previous models.\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTcocwOJjmPP"
      },
      "source": [
        "**Moore's law:**\r\n",
        "- The observation that the number of transistors in a dense integrated circuit (IC) doubles about every two years. \r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-2pJ3oDpBzH"
      },
      "source": [
        "## 02 The mathematical building blocks of neural networks ##\r\n",
        "\r\n",
        "\r\n",
        "---"
      ]
    }
  ]
}